{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d512eb7-4423-4f7a-93b3-27f37839c7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[0m\u001b[01;34mdata\u001b[0m/               \u001b[01;34mruns_multiscale_resnet\u001b[0m/        \u001b[01;34m'각종 ipynb'\u001b[0m/\n",
      " \u001b[01;34mgradcam_results\u001b[0m/    \u001b[01;34mruns_severity_classification\u001b[0m/   \u001b[01;34m김주형\u001b[0m/\n",
      " nih_train.ipynb     \u001b[01;34mruns_severity_regression\u001b[0m/      \u001b[01;34m'이전 버전'\u001b[0m/\n",
      " \u001b[01;34mruns_independent\u001b[0m/   \u001b[01;34mruns_simplified\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25d38f4d-e29c-4160-b956-423b51439ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building image path mapping...\n",
      "Found 105215 total images in directories\n",
      "Loaded 72571 images\n",
      "Building image path mapping...\n",
      "Found 105215 total images in directories\n",
      "Loaded 17731 images\n",
      "Building image path mapping...\n",
      "Found 105215 total images in directories\n",
      "Loaded 26513 images\n",
      "\n",
      "Dataset sizes:\n",
      "Train: 72571\n",
      "Val: 17731\n",
      "Test: 26513\n",
      "Warning: 874215314335715541.png not found in directories\n",
      "Warning: 00012135_003.png not found in directories\n",
      "Warning: 3061523432303694449.png not found in directories\n",
      "Warning: 00012628_064.png not found in directories\n",
      "Warning: 00011679_000.png not found in directories\n",
      "Warning: 16981847487960245462.png not found in directories\n",
      "Warning: 00013215_000.png not found in directories\n",
      "Warning: 1946623206506299537.png not found in directoriesWarning: 12797955530463069294.png not found in directories\n",
      "\n",
      "Warning: 7965441472605735445.png not found in directories\n",
      "Warning: 00012998_003.png not found in directories\n",
      "Warning: 00012749_000.png not found in directories\n",
      "Warning: 13484481163677847703.png not found in directories\n",
      "Warning: 00013602_001.png not found in directories\n",
      "Warning: 15700784749317308735.png not found in directories\n",
      "Warning: 00011605_016.png not found in directories\n",
      "Warning: 14069399327351185428.png not found in directories\n",
      "Warning: 00011936_000.png not found in directories\n",
      "Warning: 00013428_000.png not found in directories\n",
      "\n",
      "Batch shape: torch.Size([32, 3, 224, 224])\n",
      "Labels shape: torch.Size([32, 15])\n",
      "Sample labels: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "class NIHChestXrayDataset(Dataset):\n",
    "    \"\"\"NIH Chest X-ray Dataset\"\"\"\n",
    "    \n",
    "    # 15가지 질병 라벨\n",
    "    DISEASE_LABELS = [\n",
    "        'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration',\n",
    "        'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax',\n",
    "        'Consolidation', 'Edema', 'Emphysema', 'Fibrosis',\n",
    "        'Pleural_Thickening', 'Hernia', 'COVID-19'\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, data_root, metadata_path, split_file_path, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_root: 'data/nih-chest-xrays' 경로\n",
    "            metadata_path: 'total_metadata.csv' 경로\n",
    "            split_file_path: 'total_train.txt' 등의 경로\n",
    "            transform: 이미지 변환\n",
    "        \"\"\"\n",
    "        self.data_root = data_root\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 메타데이터 로드\n",
    "        self.metadata = pd.read_csv(metadata_path)\n",
    "        self.metadata.set_index('Image Index', inplace=True)\n",
    "        \n",
    "        # Split 파일 로드 (train/val/test)\n",
    "        with open(split_file_path, 'r') as f:\n",
    "            self.image_files = [line.strip() for line in f if line.strip()]\n",
    "        \n",
    "        # 모든 이미지 경로를 미리 매핑\n",
    "        print(\"Building image path mapping...\")\n",
    "        self.image_path_dict = self._build_image_paths()\n",
    "        print(f\"Loaded {len(self.image_files)} images\")\n",
    "        \n",
    "    def _build_image_paths(self):\n",
    "        \"\"\"data_root 하위의 모든 png 파일 찾아서 딕셔너리로 매핑\"\"\"\n",
    "        image_paths = {}\n",
    "        \n",
    "        # images_001 ~ images_012 탐색\n",
    "        for i in range(1, 13):\n",
    "            dir_name = f\"images_{i:03d}\"\n",
    "            pattern = os.path.join(self.data_root, dir_name, \"images\", \"*.png\")\n",
    "            for path in glob(pattern):\n",
    "                filename = os.path.basename(path)\n",
    "                image_paths[filename] = path\n",
    "        \n",
    "        # row_png 탐색\n",
    "        pattern = os.path.join(self.data_root, \"row_png\", \"*.png\")\n",
    "        for path in glob(pattern):\n",
    "            filename = os.path.basename(path)\n",
    "            image_paths[filename] = path\n",
    "        \n",
    "        print(f\"Found {len(image_paths)} total images in directories\")\n",
    "        return image_paths\n",
    "    \n",
    "    def _parse_labels(self, label_string):\n",
    "        \"\"\"라벨 문자열을 multi-hot 벡터로 변환\"\"\"\n",
    "        labels = torch.zeros(len(self.DISEASE_LABELS), dtype=torch.float32)\n",
    "        \n",
    "        if pd.isna(label_string) or label_string == 'No Finding':\n",
    "            return labels\n",
    "        \n",
    "        # '|'로 구분된 라벨들 파싱\n",
    "        diseases = label_string.split('|')\n",
    "        for disease in diseases:\n",
    "            disease = disease.strip()\n",
    "            if disease in self.DISEASE_LABELS:\n",
    "                idx = self.DISEASE_LABELS.index(disease)\n",
    "                labels[idx] = 1.0\n",
    "        \n",
    "        return labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_file = self.image_files[idx]\n",
    "        \n",
    "        # 이미지 로드\n",
    "        if image_file in self.image_path_dict:\n",
    "            img_path = self.image_path_dict[image_file]\n",
    "        else:\n",
    "            print(f\"Warning: {image_file} not found in directories\")\n",
    "            # 검은 이미지 반환\n",
    "            image = Image.new('RGB', (224, 224), color='black')\n",
    "            labels = torch.zeros(len(self.DISEASE_LABELS), dtype=torch.float32)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, labels\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            image = Image.new('RGB', (224, 224), color='black')\n",
    "        \n",
    "        # Transform 적용\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # 라벨 추출\n",
    "        if image_file in self.metadata.index:\n",
    "            label_string = self.metadata.loc[image_file, 'Finding Labels']\n",
    "            labels = self._parse_labels(label_string)\n",
    "        else:\n",
    "            print(f\"Warning: {image_file} not in metadata\")\n",
    "            labels = torch.zeros(len(self.DISEASE_LABELS), dtype=torch.float32)\n",
    "        \n",
    "        return image, labels\n",
    "\n",
    "\n",
    "def get_transforms(is_training=True, img_size=224):\n",
    "    \"\"\"기본 Transform\"\"\"\n",
    "    if is_training:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=10),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "\n",
    "def create_dataloaders(data_root, metadata_path, \n",
    "                       train_split, val_split, test_split,\n",
    "                       batch_size=32, num_workers=4, img_size=224):\n",
    "    \"\"\"DataLoader 생성\"\"\"\n",
    "    \n",
    "    train_dataset = NIHChestXrayDataset(\n",
    "        data_root=data_root,\n",
    "        metadata_path=metadata_path,\n",
    "        split_file_path=train_split,\n",
    "        transform=get_transforms(is_training=True, img_size=img_size)\n",
    "    )\n",
    "    \n",
    "    val_dataset = NIHChestXrayDataset(\n",
    "        data_root=data_root,\n",
    "        metadata_path=metadata_path,\n",
    "        split_file_path=val_split,\n",
    "        transform=get_transforms(is_training=False, img_size=img_size)\n",
    "    )\n",
    "    \n",
    "    test_dataset = NIHChestXrayDataset(\n",
    "        data_root=data_root,\n",
    "        metadata_path=metadata_path,\n",
    "        split_file_path=test_split,\n",
    "        transform=get_transforms(is_training=False, img_size=img_size)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# 사용 예제\n",
    "if __name__ == \"__main__\":\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(\n",
    "        data_root=\"data/nih-chest-xrays\",\n",
    "        metadata_path=\"data/nih-chest-xrays/total_metadata.csv\",\n",
    "        train_split=\"data/nih-chest-xrays/total_train.txt\",\n",
    "        val_split=\"data/nih-chest-xrays/total_val.txt\",\n",
    "        test_split=\"data/nih-chest-xrays/total_test.txt\",\n",
    "        batch_size=32,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nDataset sizes:\")\n",
    "    print(f\"Train: {len(train_loader.dataset)}\")\n",
    "    print(f\"Val: {len(val_loader.dataset)}\")\n",
    "    print(f\"Test: {len(test_loader.dataset)}\")\n",
    "    \n",
    "    # 샘플 확인\n",
    "    images, labels = next(iter(train_loader))\n",
    "    print(f\"\\nBatch shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Sample labels: {labels[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97bbd8ac-9e8d-4d26-a641-2cfc52158e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 파일이 존재하지 않습니다: data/nih-chest-xrays/row_png/108115246579239728.png\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "file_path = Path('data/nih-chest-xrays/row_png/108115246579239728.png')\n",
    "\n",
    "if file_path.exists():\n",
    "    print(f\"✅ 파일이 존재합니다: {file_path}\")\n",
    "else:\n",
    "    print(f\"❌ 파일이 존재하지 않습니다: {file_path}\")\n",
    "\n",
    "# 파일인지 디렉토리인지 확인\n",
    "if file_path.is_file():\n",
    "    print(\"이것은 파일입니다.\")\n",
    "elif file_path.is_dir():\n",
    "    print(\"이것은 디렉토리입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec085bb1-106f-460d-a832-358213237993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Disease Labels (15 classes):\n",
      "   0. Atelectasis\n",
      "   1. Cardiomegaly\n",
      "   2. Effusion\n",
      "   3. Infiltration\n",
      "   4. Mass\n",
      "   5. Nodule\n",
      "   6. Pneumonia\n",
      "   7. Pneumothorax\n",
      "   8. Consolidation\n",
      "   9. Edema\n",
      "  10. Emphysema\n",
      "  11. Fibrosis\n",
      "  12. Pleural_Thickening\n",
      "  13. Hernia\n",
      "  14. COVID-19\n",
      "============================================================\n",
      "\n",
      "Using device: cuda\n",
      "GPU: Tesla V100-SXM2-32GB\n",
      "GPU Memory: 34.07 GB\n",
      "\n",
      "=== Creating Train Dataset ===\n",
      "Building image path mapping...\n",
      "Found 105215 total images in directories\n",
      "Warning: 6855 files from split not found in directories\n",
      "Loaded 65716 valid images\n",
      "\n",
      "=== Creating Val Dataset ===\n",
      "Building image path mapping...\n",
      "Found 105215 total images in directories\n",
      "Warning: 1947 files from split not found in directories\n",
      "Loaded 15784 valid images\n",
      "\n",
      "=== Creating Test Dataset ===\n",
      "Building image path mapping...\n",
      "Found 105215 total images in directories\n",
      "Warning: 2798 files from split not found in directories\n",
      "Loaded 23715 valid images\n",
      "\n",
      "============================================================\n",
      "Dataset Summary:\n",
      "  Train: 65,716 images (1026 batches)\n",
      "  Val:   15,784 images (247 batches)\n",
      "  Test:  23,715 images (371 batches)\n",
      "  Batch Size: 64\n",
      "============================================================\n",
      "\n",
      "=== Creating Model ===\n",
      "Loaded pretrained model: densenet121-res224-all\n",
      "Original output classes: 18\n",
      "Model created with 15 output classes\n",
      "\n",
      "============================================================\n",
      "=== Training Start ===\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Epoch [1/50]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Train - Loss: 0.1430, Acc: 0.9579, Exact Match: 0.5799\n",
      "✓ Val   - Loss: 0.1288, Acc: 0.9597, Exact Match: 0.5920\n",
      "✓ LR: 0.001000\n",
      "★ Best model saved! (Val Loss: 0.1288)\n",
      "\n",
      "============================================================\n",
      "Epoch [2/50]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Train - Loss: 0.1294, Acc: 0.9588, Exact Match: 0.5827\n",
      "✓ Val   - Loss: 0.1264, Acc: 0.9599, Exact Match: 0.5910\n",
      "✓ LR: 0.001000\n",
      "★ Best model saved! (Val Loss: 0.1264)\n",
      "\n",
      "============================================================\n",
      "Epoch [3/50]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Train - Loss: 0.1276, Acc: 0.9589, Exact Match: 0.5835\n",
      "✓ Val   - Loss: 0.1280, Acc: 0.9598, Exact Match: 0.5902\n",
      "✓ LR: 0.001000\n",
      "\n",
      "============================================================\n",
      "Epoch [4/50]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Train - Loss: 0.1263, Acc: 0.9590, Exact Match: 0.5834\n",
      "✓ Val   - Loss: 0.1277, Acc: 0.9600, Exact Match: 0.5933\n",
      "✓ LR: 0.001000\n",
      "\n",
      "============================================================\n",
      "Epoch [5/50]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Train - Loss: 0.1252, Acc: 0.9592, Exact Match: 0.5848\n",
      "✓ Val   - Loss: 0.1252, Acc: 0.9599, Exact Match: 0.5908\n",
      "✓ LR: 0.001000\n",
      "★ Best model saved! (Val Loss: 0.1252)\n",
      "\n",
      "============================================================\n",
      "Epoch [6/50]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Train - Loss: 0.1241, Acc: 0.9593, Exact Match: 0.5853\n",
      "✓ Val   - Loss: 0.1285, Acc: 0.9597, Exact Match: 0.5907\n",
      "✓ LR: 0.001000\n",
      "\n",
      "============================================================\n",
      "Epoch [7/50]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Train - Loss: 0.1234, Acc: 0.9593, Exact Match: 0.5851\n",
      "✓ Val   - Loss: 0.1311, Acc: 0.9595, Exact Match: 0.5889\n",
      "✓ LR: 0.001000\n",
      "\n",
      "============================================================\n",
      "Epoch [8/50]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Train - Loss: 0.1224, Acc: 0.9596, Exact Match: 0.5869\n",
      "✓ Val   - Loss: 0.1244, Acc: 0.9596, Exact Match: 0.5872\n",
      "✓ LR: 0.001000\n",
      "★ Best model saved! (Val Loss: 0.1244)\n",
      "\n",
      "============================================================\n",
      "Epoch [9/50]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Train - Loss: 0.1218, Acc: 0.9595, Exact Match: 0.5858\n",
      "✓ Val   - Loss: 0.1256, Acc: 0.9597, Exact Match: 0.5883\n",
      "✓ LR: 0.001000\n",
      "\n",
      "============================================================\n",
      "Epoch [10/50]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Train - Loss: 0.1211, Acc: 0.9596, Exact Match: 0.5865\n",
      "✓ Val   - Loss: 0.1293, Acc: 0.9596, Exact Match: 0.5887\n",
      "✓ LR: 0.001000\n",
      "\n",
      "============================================================\n",
      "Epoch [11/50]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Train - Loss: 0.1205, Acc: 0.9598, Exact Match: 0.5878\n",
      "✓ Val   - Loss: 0.1234, Acc: 0.9596, Exact Match: 0.5880\n",
      "✓ LR: 0.001000\n",
      "★ Best model saved! (Val Loss: 0.1234)\n",
      "\n",
      "============================================================\n",
      "Epoch [12/50]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Train - Loss: 0.1199, Acc: 0.9598, Exact Match: 0.5876\n",
      "✓ Val   - Loss: 0.1236, Acc: 0.9597, Exact Match: 0.5889\n",
      "✓ LR: 0.001000\n",
      "\n",
      "============================================================\n",
      "Epoch [13/50]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Train - Loss: 0.1192, Acc: 0.9599, Exact Match: 0.5876\n",
      "✓ Val   - Loss: 0.1255, Acc: 0.9595, Exact Match: 0.5860\n",
      "✓ LR: 0.001000\n",
      "\n",
      "============================================================\n",
      "Epoch [14/50]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Train - Loss: 0.1185, Acc: 0.9600, Exact Match: 0.5884\n",
      "✓ Val   - Loss: 0.1357, Acc: 0.9596, Exact Match: 0.5909\n",
      "✓ LR: 0.001000\n",
      "\n",
      "============================================================\n",
      "Epoch [15/50]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Train - Loss: 0.1180, Acc: 0.9601, Exact Match: 0.5893\n",
      "✓ Val   - Loss: 0.1260, Acc: 0.9598, Exact Match: 0.5897\n",
      "✓ LR: 0.000500\n",
      "\n",
      "============================================================\n",
      "Epoch [16/50]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Train - Loss: 0.1150, Acc: 0.9605, Exact Match: 0.5916\n",
      "✓ Val   - Loss: 0.1242, Acc: 0.9597, Exact Match: 0.5874\n",
      "✓ LR: 0.000500\n",
      "\n",
      "============================================================\n",
      "Epoch [17/50]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Train - Loss: 0.1142, Acc: 0.9608, Exact Match: 0.5926\n",
      "✓ Val   - Loss: 0.1246, Acc: 0.9597, Exact Match: 0.5880\n",
      "✓ LR: 0.000500\n",
      "\n",
      "============================================================\n",
      "Epoch [18/50]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Train - Loss: 0.1134, Acc: 0.9608, Exact Match: 0.5938\n",
      "✓ Val   - Loss: 0.1255, Acc: 0.9596, Exact Match: 0.5879\n",
      "✓ LR: 0.000500\n",
      "\n",
      "⚠ Early stopping triggered at epoch 18\n",
      "\n",
      "============================================================\n",
      "=== Training Completed ===\n",
      "Best Val Loss: 0.1234\n",
      "============================================================\n",
      "\n",
      "✓ Training history plot saved to: training_history.png\n",
      "\n",
      "=== Testing on Best Model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Test Results:\n",
      "  Loss: 0.1941\n",
      "  Per-Label Accuracy: 0.9303\n",
      "  Exact Match Accuracy: 0.3792\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Final Summary:\n",
      "  Best Val Loss: 0.1234\n",
      "  Test Loss: 0.1941\n",
      "  Test Accuracy: 0.9303\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from glob import glob\n",
    "import torchxrayvision as xrv\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NIHChestXrayDataset(Dataset):\n",
    "    \"\"\"NIH + Brixia(COVID-19) Chest X-ray Dataset\"\"\"\n",
    "    \n",
    "    # 15가지 질병 라벨 (COVID-19 추가!)\n",
    "    DISEASE_LABELS = [\n",
    "        'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration',\n",
    "        'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax',\n",
    "        'Consolidation', 'Edema', 'Emphysema', 'Fibrosis',\n",
    "        'Pleural_Thickening', 'Hernia', 'COVID-19'\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, data_root, metadata_path, split_file_path, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_root: 'data/nih-chest-xrays' 경로\n",
    "            metadata_path: 'total_metadata.csv' 경로\n",
    "            split_file_path: 'total_train.txt' 등의 경로\n",
    "            transform: 이미지 변환\n",
    "        \"\"\"\n",
    "        self.data_root = data_root\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 메타데이터 로드\n",
    "        self.metadata = pd.read_csv(metadata_path, low_memory=False)\n",
    "        self.metadata.set_index('Image Index', inplace=True)\n",
    "        \n",
    "        # 모든 이미지 경로를 미리 매핑\n",
    "        print(\"Building image path mapping...\")\n",
    "        self.image_path_dict = self._build_image_paths()\n",
    "        print(f\"Found {len(self.image_path_dict)} total images in directories\")\n",
    "        \n",
    "        # Split 파일 로드 후 실제 존재하는 파일만 필터링\n",
    "        with open(split_file_path, 'r') as f:\n",
    "            all_files = [line.strip() for line in f if line.strip()]\n",
    "        \n",
    "        # 실제 존재하는 파일만 남김\n",
    "        self.image_files = [f for f in all_files if f in self.image_path_dict]\n",
    "        \n",
    "        missing = len(all_files) - len(self.image_files)\n",
    "        if missing > 0:\n",
    "            print(f\"Warning: {missing} files from split not found in directories\")\n",
    "        \n",
    "        print(f\"Loaded {len(self.image_files)} valid images\")\n",
    "        \n",
    "    def _build_image_paths(self):\n",
    "        \"\"\"data_root 하위의 모든 png 파일 찾아서 딕셔너리로 매핑\"\"\"\n",
    "        image_paths = {}\n",
    "        \n",
    "        # images_001 ~ images_012 탐색\n",
    "        for i in range(1, 13):\n",
    "            dir_name = f\"images_{i:03d}\"\n",
    "            pattern = os.path.join(self.data_root, dir_name, \"images\", \"*.png\")\n",
    "            for path in glob(pattern):\n",
    "                filename = os.path.basename(path)\n",
    "                image_paths[filename] = path\n",
    "        \n",
    "        # row_png 탐색 (Brixia COVID-19)\n",
    "        pattern = os.path.join(self.data_root, \"row_png\", \"*.png\")\n",
    "        for path in glob(pattern):\n",
    "            filename = os.path.basename(path)\n",
    "            image_paths[filename] = path\n",
    "        \n",
    "        return image_paths\n",
    "    \n",
    "    def _parse_labels(self, label_string):\n",
    "        \"\"\"라벨 문자열을 multi-hot 벡터로 변환\"\"\"\n",
    "        labels = torch.zeros(len(self.DISEASE_LABELS), dtype=torch.float32)\n",
    "        \n",
    "        if pd.isna(label_string) or label_string == 'No Finding':\n",
    "            return labels\n",
    "        \n",
    "        # '|'로 구분된 라벨들 파싱\n",
    "        diseases = label_string.split('|')\n",
    "        for disease in diseases:\n",
    "            disease = disease.strip()\n",
    "            if disease in self.DISEASE_LABELS:\n",
    "                idx = self.DISEASE_LABELS.index(disease)\n",
    "                labels[idx] = 1.0\n",
    "        \n",
    "        return labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_file = self.image_files[idx]\n",
    "        \n",
    "        # 이미지 로드 (GRAYSCALE for TorchXRayVision!)\n",
    "        img_path = self.image_path_dict[image_file]\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('L')  # Grayscale!\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            image = Image.new('L', (224, 224), color=0)\n",
    "        \n",
    "        # Transform 적용\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # 라벨 추출\n",
    "        if image_file in self.metadata.index:\n",
    "            label_string = self.metadata.loc[image_file, 'Finding Labels']\n",
    "            labels = self._parse_labels(label_string)\n",
    "        else:\n",
    "            # 메타데이터에 없으면 0 벡터\n",
    "            labels = torch.zeros(len(self.DISEASE_LABELS), dtype=torch.float32)\n",
    "        \n",
    "        return image, labels\n",
    "\n",
    "\n",
    "def get_transforms(is_training=True, img_size=224):\n",
    "    \"\"\"Grayscale Transform for TorchXRayVision\"\"\"\n",
    "    if is_training:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=10),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "            transforms.ToTensor(),\n",
    "            # TorchXRayVision expects normalized images\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "\n",
    "def create_dataloaders(data_root, metadata_path, \n",
    "                       train_split, val_split, test_split,\n",
    "                       batch_size=32, num_workers=4, img_size=224):\n",
    "    \"\"\"DataLoader 생성\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Creating Train Dataset ===\")\n",
    "    train_dataset = NIHChestXrayDataset(\n",
    "        data_root=data_root,\n",
    "        metadata_path=metadata_path,\n",
    "        split_file_path=train_split,\n",
    "        transform=get_transforms(is_training=True, img_size=img_size)\n",
    "    )\n",
    "    \n",
    "    print(\"\\n=== Creating Val Dataset ===\")\n",
    "    val_dataset = NIHChestXrayDataset(\n",
    "        data_root=data_root,\n",
    "        metadata_path=metadata_path,\n",
    "        split_file_path=val_split,\n",
    "        transform=get_transforms(is_training=False, img_size=img_size)\n",
    "    )\n",
    "    \n",
    "    print(\"\\n=== Creating Test Dataset ===\")\n",
    "    test_dataset = NIHChestXrayDataset(\n",
    "        data_root=data_root,\n",
    "        metadata_path=metadata_path,\n",
    "        split_file_path=test_split,\n",
    "        transform=get_transforms(is_training=False, img_size=img_size)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "class XRayMultiLabelClassifier(nn.Module):\n",
    "    \"\"\"TorchXRayVision 기반 다중라벨 분류 모델\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=15, pretrained=True, model_name='densenet121-res224-all'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes: 출력 클래스 수 (NIH 14 + COVID-19 = 15)\n",
    "            pretrained: TorchXRayVision 사전학습 가중치 사용 여부\n",
    "            model_name: 모델 종류\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        if pretrained:\n",
    "            # TorchXRayVision 사전학습 모델 로드\n",
    "            self.backbone = xrv.models.DenseNet(weights=model_name)\n",
    "            print(f\"Loaded pretrained model: {model_name}\")\n",
    "            print(f\"Original output classes: {self.backbone.classifier.out_features}\")\n",
    "        else:\n",
    "            # 사전학습 없이 초기화\n",
    "            self.backbone = xrv.models.DenseNet(weights=None)\n",
    "        \n",
    "        # 기존 classifier 교체 (15 classes)\n",
    "        in_features = self.backbone.classifier.in_features\n",
    "        self.backbone.classifier = nn.Linear(in_features, num_classes)\n",
    "        self.backbone.op_threshs = None\n",
    "        \n",
    "        print(f\"Model created with {num_classes} output classes\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "\n",
    "def calculate_metrics(outputs, labels, threshold=0.5):\n",
    "    \"\"\"정확도 계산\"\"\"\n",
    "    preds = (torch.sigmoid(outputs) > threshold).float()\n",
    "    correct = (preds == labels).float()\n",
    "    \n",
    "    # Per-sample accuracy (모든 라벨이 정확히 맞은 비율)\n",
    "    exact_match = (correct.sum(dim=1) == labels.size(1)).float().mean()\n",
    "    \n",
    "    # Per-label accuracy (각 라벨별 정확도 평균)\n",
    "    per_label_acc = correct.mean()\n",
    "    \n",
    "    return exact_match.item(), per_label_acc.item()\n",
    "\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device):\n",
    "    \"\"\"1 epoch 학습 with AMP\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_exact_match = 0.0\n",
    "    total_per_label_acc = 0.0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed Precision Training\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward with scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # Metrics\n",
    "        exact_match, per_label_acc = calculate_metrics(outputs, labels)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_exact_match += exact_match\n",
    "        total_per_label_acc += per_label_acc\n",
    "        \n",
    "        # Progress bar 업데이트\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{per_label_acc:.4f}'\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_exact_match = total_exact_match / len(train_loader)\n",
    "    avg_per_label_acc = total_per_label_acc / len(train_loader)\n",
    "    \n",
    "    return avg_loss, avg_exact_match, avg_per_label_acc\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"검증\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_exact_match = 0.0\n",
    "    total_per_label_acc = 0.0\n",
    "    \n",
    "    pbar = tqdm(val_loader, desc=\"Validation\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in pbar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Metrics\n",
    "            exact_match, per_label_acc = calculate_metrics(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_exact_match += exact_match\n",
    "            total_per_label_acc += per_label_acc\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{per_label_acc:.4f}'\n",
    "            })\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    avg_exact_match = total_exact_match / len(val_loader)\n",
    "    avg_per_label_acc = total_per_label_acc / len(val_loader)\n",
    "    \n",
    "    return avg_loss, avg_exact_match, avg_per_label_acc\n",
    "\n",
    "\n",
    "def plot_training_history(history, save_path='training_history.png'):\n",
    "    \"\"\"학습 히스토리 시각화\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "    axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training & Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    axes[1].plot(history['train_acc'], label='Train Acc', marker='o')\n",
    "    axes[1].plot(history['val_acc'], label='Val Acc', marker='s')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Training & Validation Accuracy (Per-Label)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"\\n✓ Training history plot saved to: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early Stopping\"\"\"\n",
    "    def __init__(self, patience=5, min_delta=0.0, mode='min'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            return False\n",
    "        \n",
    "        if self.mode == 'min':\n",
    "            improved = score < (self.best_score - self.min_delta)\n",
    "        else:\n",
    "            improved = score > (self.best_score + self.min_delta)\n",
    "        \n",
    "        if improved:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "\n",
    "def main():\n",
    "    # ==================== 설정 ====================\n",
    "    DATA_ROOT = \"data/nih-chest-xrays\"\n",
    "    METADATA_PATH = \"data/nih-chest-xrays/total_metadata.csv\"\n",
    "    TRAIN_SPLIT = \"data/nih-chest-xrays/total_train.txt\"\n",
    "    VAL_SPLIT = \"data/nih-chest-xrays/total_val.txt\"\n",
    "    TEST_SPLIT = \"data/nih-chest-xrays/total_test.txt\"\n",
    "    \n",
    "    BATCH_SIZE = 64  # V100 32GB -> 배치 크기 증가\n",
    "    NUM_WORKERS = 8\n",
    "    IMG_SIZE = 224\n",
    "    NUM_EPOCHS = 50\n",
    "    LEARNING_RATE = 0.001\n",
    "    NUM_CLASSES = 15  # NIH 14 + COVID-19 1\n",
    "    EARLY_STOPPING_PATIENCE = 7\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    \n",
    "    # ==================== DataLoader 생성 ====================\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(\n",
    "        data_root=DATA_ROOT,\n",
    "        metadata_path=METADATA_PATH,\n",
    "        train_split=TRAIN_SPLIT,\n",
    "        val_split=VAL_SPLIT,\n",
    "        test_split=TEST_SPLIT,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        img_size=IMG_SIZE\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Dataset Summary:\")\n",
    "    print(f\"  Train: {len(train_loader.dataset):,} images ({len(train_loader)} batches)\")\n",
    "    print(f\"  Val:   {len(val_loader.dataset):,} images ({len(val_loader)} batches)\")\n",
    "    print(f\"  Test:  {len(test_loader.dataset):,} images ({len(test_loader)} batches)\")\n",
    "    print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # ==================== 모델 생성 ====================\n",
    "    print(\"=== Creating Model ===\")\n",
    "    model = XRayMultiLabelClassifier(\n",
    "        num_classes=NUM_CLASSES,\n",
    "        pretrained=True,\n",
    "        model_name='densenet121-res224-all'\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # ==================== Loss & Optimizer ====================\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Mixed Precision Scaler\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # Early Stopping\n",
    "    early_stopping = EarlyStopping(patience=EARLY_STOPPING_PATIENCE, mode='min')\n",
    "    \n",
    "    # ==================== 학습 ====================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"=== Training Start ===\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_acc': [], 'val_acc': [],\n",
    "        'train_exact_match': [], 'val_exact_match': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}]\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_exact, train_acc = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, scaler, device\n",
    "        )\n",
    "        \n",
    "        # Validation\n",
    "        val_loss, val_exact, val_acc = validate(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(val_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # History 저장\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['train_exact_match'].append(train_exact)\n",
    "        history['val_exact_match'].append(val_exact)\n",
    "        \n",
    "        # 결과 출력\n",
    "        print(f\"\\n✓ Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, Exact Match: {train_exact:.4f}\")\n",
    "        print(f\"✓ Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, Exact Match: {val_exact:.4f}\")\n",
    "        print(f\"✓ LR: {current_lr:.6f}\")\n",
    "        \n",
    "        # 모델 저장\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'val_acc': val_acc,\n",
    "            }, 'best_model.pth')\n",
    "            print(f\"★ Best model saved! (Val Loss: {val_loss:.4f})\")\n",
    "        \n",
    "        # Early Stopping 체크\n",
    "        if early_stopping(val_loss):\n",
    "            print(f\"\\n⚠ Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # ==================== 학습 완료 ====================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"=== Training Completed ===\")\n",
    "    print(f\"Best Val Loss: {best_val_loss:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 학습 히스토리 플롯\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # ==================== Test 평가 ====================\n",
    "    print(\"\\n=== Testing on Best Model ===\")\n",
    "    checkpoint = torch.load('best_model.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    test_loss, test_exact, test_acc = validate(model, test_loader, criterion, device)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Test Results:\")\n",
    "    print(f\"  Loss: {test_loss:.4f}\")\n",
    "    print(f\"  Per-Label Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"  Exact Match Accuracy: {test_exact:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 최종 결과 요약\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Final Summary:\")\n",
    "    print(f\"  Best Val Loss: {best_val_loss:.4f}\")\n",
    "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 질병 라벨 출력\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Disease Labels (15 classes):\")\n",
    "    for i, label in enumerate(NIHChestXrayDataset.DISEASE_LABELS):\n",
    "        print(f\"  {i:2d}. {label}\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82798b80-fcf2-40be-baa4-e8d4fc87a8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
